{
  "title": "PRIME",
  "url": "https://wiki.archlinux.org/title/PRIME",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "Related articles\n\n- NVIDIA Optimus\n- External GPU\n\nPRIME is a technology used to manage hybrid graphics found on recent desktops and laptops (Optimus for NVIDIA, AMD Dynamic Switchable Graphics for Radeon). PRIME GPU offloading and Reverse PRIME are an attempt to support muxless hybrid graphics in the Linux kernel.\n\n"
    },
    {
      "title": "PRIME GPU offloading",
      "level": 2,
      "content": "We want to render applications on the more powerful card and send the result to the card which has display connected.\n\nThe command xrandr --setprovideroffloadsink provider sink can be used to make a render offload provider send its output to the sink provider (the provider which has a display connected). The provider and sink identifiers can be numeric (0x7d, 0x56) or a case-sensitive name (Intel, radeon).\n\nExample:\n\n```\n$ xrandr --setprovideroffloadsink radeon Intel\n```\n\nYou may also use provider index instead of provider name:\n\n```\n$ xrandr --setprovideroffloadsink 1 0\n```\n\nNote: **This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.** This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.\n\nThis article or section needs language, wiki syntax or style improvements. See Help:Style for reference.\n\n"
    },
    {
      "title": "For open source drivers - PRIME",
      "level": 3,
      "content": "To use your discrete card for the applications who need it the most (for example games, 3D modellers...), prepend the DRI_PRIME=1 environment variable:\n\n```\n$ DRI_PRIME=1 glxinfo | grep \"OpenGL renderer\"\n```\n\n```\nOpenGL renderer string: Gallium 0.4 on AMD TURKS\n```\n\nOther applications will still use the less power-hungry integrated card. These settings are lost once the X server restarts, you may want to make a script and auto-run it at the startup of your desktop environment (alternatively, put it in /etc/X11/xinit/xinitrc.d/). This may reduce your battery life and increase heat though.\n\nSee Gentoo:AMDGPU#Identifying_which_graphics_card_is_in_use for more information.\n\nFor DRI_PRIME to work on Vulkan applications vulkan-mesa-layers needs to be installed, as well as lib32-vulkan-mesa-layers for 32 bit applications.\n\n"
    },
    {
      "title": "PRIME render offload",
      "level": 3,
      "content": "NVIDIA driver since version 435.17 supports this method. The modesetting, xf86-video-amdgpu (450.57), and xf86-video-intel (455.38) are officially supported as iGPU drivers.\n\nTo run a program on the NVIDIA card you can use the prime-run script provided by nvidia-prime:\n\n```\n$ prime-run glxinfo | grep \"OpenGL renderer\"\n$ prime-run vulkaninfo\n```\n\n"
    },
    {
      "title": "PCI-Express Runtime D3 (RTD3) Power Management",
      "level": 4,
      "content": "Kernel PCI power management turns off the GPU when not used with PRIME offloading or reverse PRIME. This feature is supported by modesetting, xf86-video-amdgpu, xf86-video-intel, xf86-video-nouveau drivers.\n\nThe following command can be used to check current [1] power state of each GPU:\n\n```\n$ cat /sys/class/drm/card*/device/power_state\n```\n\n- No configuration is generally needed for Ampere as this is enabled by default. For some Ampere users, udev rules may be necessary.\n- Some users with hybrid graphics are reporting that their discrete NVIDIA Ampere GPUs are failing to remain in the D3Cold power state after upgrading to newer NVIDIA drivers (seemingly >525) [2].\n- Some users with pre-Ampere card and broken D3 support on newer drivers reported a workaround to disable the GSP firmware with NVreg_EnableGpuFirmware=0[3].\n\nFor Turing generation cards with Intel Coffee Lake or above CPUs as well as some Ryzen CPUs like the 5800H, it is possible to fully power down the GPU when not in use.\n\nThe following udev rules are needed, as recommended by NVIDIA:\n\n```\n/etc/udev/rules.d/80-nvidia-pm.rules\n```\n\n```\n# Enable runtime PM for NVIDIA VGA/3D controller devices on driver bind\nACTION==\"bind\", SUBSYSTEM==\"pci\", ATTR{vendor}==\"0x10de\", ATTR{class}==\"0x030000\", TEST==\"power/control\", ATTR{power/control}=\"auto\"\nACTION==\"bind\", SUBSYSTEM==\"pci\", ATTR{vendor}==\"0x10de\", ATTR{class}==\"0x030200\", TEST==\"power/control\", ATTR{power/control}=\"auto\"\n\n# Disable runtime PM for NVIDIA VGA/3D controller devices on driver unbind\nACTION==\"unbind\", SUBSYSTEM==\"pci\", ATTR{vendor}==\"0x10de\", ATTR{class}==\"0x030000\", TEST==\"power/control\", ATTR{power/control}=\"on\"\nACTION==\"unbind\", SUBSYSTEM==\"pci\", ATTR{vendor}==\"0x10de\", ATTR{class}==\"0x030200\", TEST==\"power/control\", ATTR{power/control}=\"on\"\n```\n\nSome users also reported that the following additional lines are necessary too:\n\n```\n/etc/udev/rules.d/80-nvidia-pm.rules\n```\n\n```\n# Enable runtime PM for NVIDIA VGA/3D controller devices on adding device\nACTION==\"add\", SUBSYSTEM==\"pci\", ATTR{vendor}==\"0x10de\", ATTR{class}==\"0x030000\", TEST==\"power/control\", ATTR{power/control}=\"auto\"\nACTION==\"add\", SUBSYSTEM==\"pci\", ATTR{vendor}==\"0x10de\", ATTR{class}==\"0x030200\", TEST==\"power/control\", ATTR{power/control}=\"auto\"\n```\n\nAlso, add the following module parameters:\n\n```\n/etc/modprobe.d/nvidia-pm.conf\n```\n\n```\noptions nvidia \"NVreg_DynamicPowerManagement=0x02\"\n```\n\nAlternatively, you can install nvidia-prime-rtd3pmAUR which provides these two configuration files.\n\nAfter you setup the udev rules and the module parameter either manually or using the AUR package, you will need to restart your Laptop.\n\nTo check if the NVIDIA GPU is turned off you can use this command:\n\n```\n$ cat /sys/bus/pci/devices/0000:01:00.0/power/runtime_status\n```\n\nYou will see either suspended or running, if suspended is displayed, the GPU is turned off. Now the power draw will be 0 Watts, making the battery last longer.\n\nIn some cases, such as the NVIDIA RTX A1000, none of the options above might be listed and instead the result will be active. This alone does not mean that the GPU is in the running state. In this case you can check the state using this command:\n\n```\n$ cat /sys/bus/pci/devices/0000:01:00.0/power/runtime_suspended_time\n```\n\nWhile the GPU is in suspended state, the counter will be incrementing every time you run the command. When the GPU's state becomes running it will stop incrementing.\n\nIf you notice that the runtime_suspended_time is not incrementing, you can check your D3 Status with this command.\n\n```\n$ cat /proc/driver/nvidia/gpus/0000:01:00.0/power\n```\n\nIf it says Runtime D3 status: Not supported, you may need to follow the steps in this forum post to disable. One user noted disabling the GpuFirmware only works on the closed source driver, not on nvidia-open.\n\nWe also need to enable nvidia-persistenced.service to avoid the kernel tearing down the device state whenever the NVIDIA device resources are no longer in use. [4]\n\n"
    },
    {
      "title": "Configure applications to render using GPU",
      "level": 4,
      "content": "Note: **This article or section is a candidate for merging with External GPU#Xorg rendered on iGPU, PRIME render offload to eGPU.** This article or section is a candidate for merging with External GPU#Xorg rendered on iGPU, PRIME render offload to eGPU.\n\nThis article or section is a candidate for merging with External GPU#Xorg rendered on iGPU, PRIME render offload to eGPU.\n\nEven without enabling Dynamic Power Management, offload rendering of applications is required [5].\n\nTo run an application offloaded to the NVIDIA GPU with Dynamic Power Management enabled, add the following environment variables: [6]\n\n```\n__NV_PRIME_RENDER_OFFLOAD=1 __GLX_VENDOR_LIBRARY_NAME=nvidia command\n```\n\nWhen using on a Steam game, the launcher command line can be set to:\n\n```\n__NV_PRIME_RENDER_OFFLOAD=1 __GLX_VENDOR_LIBRARY_NAME=nvidia %command%\n```\n\n"
    },
    {
      "title": "GNOME integration",
      "level": 4,
      "content": "For GNOME integration, install switcheroo-control and enable switcheroo-control.service.\n\nGNOME will respect the PrefersNonDefaultGPU property in the desktop entry. Alternatively, you can launch applications with GPU by right clicking on the icon and choosing Launch using Discrete Graphics Card.\n\n"
    },
    {
      "title": "Troubleshooting",
      "level": 4,
      "content": "If you have bumblebee installed, you should remove it because it blacklists the nvidia_drm driver which is required to load the NVIDIA driver by X server for offloading.\n\n"
    },
    {
      "title": "PRIME synchronization",
      "level": 3,
      "content": "When using PRIME, the primary GPU renders the screen content / applications, and passes it to the secondary GPU for display. Quoting an NVIDIA thread, \"Traditional vsync can synchronize the rendering of the application with the copy into system memory, but there needs to be an additional mechanism to synchronize the copy into system memory with the iGPU’s display engine. Such a mechanism would have to involve communication between the dGPU’s and the iGPU’s drivers, unlike traditional vsync.\"\n\nThis synchronization is achieved using PRIME sync. To check if PRIME synchronization is enabled for your display, check the output of xrandr --prop.\n\nTo enable it run:\n\n```\n$ xrandr --output <output-name> --set \"PRIME Synchronization\" 1\n```\n\n- A pre-requisite for PRIME synchronization with the NVIDIA driver is to enable modesetting.\n- PRIME synchronization is not available with the AMDGPU DDX driver (xf86-video-amdgpu).\n\n"
    },
    {
      "title": "Reverse PRIME",
      "level": 2,
      "content": "Note: **This article or section needs expansion.** This article or section needs expansion.\n\nThis article or section needs expansion.\n\n- Reverse PRIME is not supported for AMDGPU + NVIDIA on NVIDIA driver prior to 470 beta. See [7] for more details.\n- Currently when only external display is enabled, you will only get 1 FPS. See [8] for more details, but a workaround is most likely to export \"LIBGL_DRI3_DISABLE=true\"\n\nIf the second GPU has outputs that are not accessible by the primary GPU, you can use Reverse PRIME to make use of them. This will involve using the primary GPU to render the images, and then pass them off to the second GPU.\n\nIt may work out of the box, however if not, please go through the following steps.\n\n"
    },
    {
      "title": "Configuration",
      "level": 3,
      "content": "Note: **This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.** This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.\n\nThis article or section needs language, wiki syntax or style improvements. See Help:Style for reference.\n\nFirst, identify integrated GPU BusID\n\n```\nlspci -d ::03xx\n```\n\n```\n00:02.0 VGA compatible controller: Intel Corporation UHD Graphics 630 (Mobile)\n01:00.0 VGA compatible controller: NVIDIA Corporation TU117M [GeForce GTX 1650 Mobile / Max-Q] (rev a1)\n```\n\nIn the above example Intel card has 00:02.0 which translates to PCI:0:2:0.\n\nSet up your xorg.conf as follows and adjust BusID.\n\n```\n/etc/X11/xorg.conf\n```\n\n```\nSection \"ServerLayout\"\n        Identifier \"layout\"\n        Screen 0 \"intel\"\n        Inactive \"nvidia\"\n        Option \"AllowNVIDIAGPUScreens\"\nEndSection\n\nSection \"Device\"\n        Identifier \"nvidia\"\n        Driver \"nvidia\"\nEndSection\n\nSection \"Screen\"\n        Identifier \"nvidia\"\n        Device \"nvidia\"\nEndSection\n\nSection \"Device\"\n        Identifier \"intel\"\n        Driver \"modesetting\"\n        BusID \"PCI:0:2:0\"\nEndSection\n\nSection \"Screen\"\n        Identifier \"intel\"\n        Device \"intel\"\nEndSection\n```\n\nThe command xrandr --setprovideroutputsource provider source sets the provider as output for the source. For example:\n\n```\n$ xrandr --setprovideroutputsource radeon Intel\n```\n\nWhen this is done, the discrete card's outputs should be available in xrandr, and you could do something like:\n\n```\n$ xrandr --output HDMI-1 --auto --above LVDS1\n```\n\nto configure both internal as well as external displays.\n\n"
    },
    {
      "title": "Known issues",
      "level": 3,
      "content": "If after reboot you only have one provider, it might be because when Xorg starts, the nvidia module is not loaded yet. You need to enable early module loading. See NVIDIA#Early loading for details.\n\n"
    },
    {
      "title": "Troubleshooting",
      "level": 2,
      "content": "Note: **The factual accuracy of this article or section is disputed.** The factual accuracy of this article or section is disputed.\n\nThe factual accuracy of this article or section is disputed.\n\n"
    },
    {
      "title": "XRandR specifies only 1 output provider",
      "level": 3,
      "content": "Delete/move /etc/X11/xorg.conf file and any other files relating to GPUs in /etc/X11/xorg.conf.d/. Restart the X server after this change.\n\nIf the video driver is blacklisted in /etc/modprobe.d/ or /usr/lib/modprobe.d/, load the module and restart X. This may be the case if you use the bbswitch module for NVIDIA GPUs.\n\nAnother possible problem is that Xorg might try to automatically assign monitors to your second GPU. Check the logs:\n\n```\n$ grep \"No modes\" ~/.local/share/xorg/Xorg.0.log\n```\n\n```\nAMDGPU(0): No modes.\n```\n\nTo solve this add the ServerLayout section with inactive device to your xorg.conf:\n\n```\n/etc/X11/xorg.conf\n```\n\n```\nSection \"ServerLayout\"\n  Identifier     \"X.org Configured\"\n  Screen      0  \"Screen0\" 0 0 # Screen for your primary GPU\n  Inactive       \"Card1\"       # Device for your second GPU\nEndSection\n```\n\n"
    },
    {
      "title": "When an application is rendered with the discrete card, it only renders a black screen",
      "level": 3,
      "content": "In some cases PRIME needs a composite manager to properly work. If your window manager does not handle compositing, you can use a compositor on top of it.\n\nIf you use Xfce, you can go to Menu > Settings > Window Manager Tweaks > Compositor and enable compositing, then try again your application.\n\n"
    },
    {
      "title": "Black screen with GL-based compositors",
      "level": 4,
      "content": "Currently there are issues with GL-based compositors and PRIME offloading. While Xrender-based compositors (xcompmgr, xfwm, compton's default backend, cairo-compmgr, and a few others) will work without issue, GL-based compositors (Mutter/muffin, Compiz, compton with GLX backend, Kwin's OpenGL backend, etc) will initially show a black screen, as if there was no compositor running. While you can force an image to appear by resizing the offloaded window, this is not a practical solution as it will not work for things such as full screen Wine applications. This means that desktop environments such as GNOME3 and Cinnamon have issues with using PRIME offloading.\n\nAdditionally if you are using an Intel IGP you might be able to fix the GL Compositing issue by running the IGP as UXA instead of SNA, however this may cause issues with the offloading process (ie, xrandr --listproviders may not list the discrete GPU).\n\nFor details see FDO Bug #69101.\n\nOne other way to approach this issue is by enabling DRI3 in the Intel driver. See the below issue for a sample configuration.\n\nYou may find that disabling fullscreen undirect allows PRIME offloading to work correctly for full-screen applications.\n\n"
    },
    {
      "title": "Kernel crash/oops when using PRIME and switching windows/workspaces",
      "level": 3,
      "content": "Using DRI3 WITH a configuration file for the integrated card seems to fix this issue.\n\nTo enable DRI3, you need to create a configuration for the integrated card adding the DRI3 option:\n\n```\nSection \"Device\"\n    Identifier \"Intel Graphics\"\n    Driver \"intel\"\n    Option \"DRI\" \"3\"\nEndSection\n```\n\nAfter this you can use DRI_PRIME=1 WITHOUT having to run xrandr --setprovideroffloadsink radeon Intel as DRI3 will take care of the offloading.\n\n"
    },
    {
      "title": "Glitches/Ghosting synchronization problem on second monitor when using reverse PRIME",
      "level": 3,
      "content": "This problem can affect users when not using a composite manager, such as with i3. [9]\n\nIf you experience this problem under Gnome, then a possible fix is to set some environment variables in /etc/environment [10]\n\n```\nCLUTTER_PAINT=disable-clipped-redraws:disable-culling\nCLUTTER_VBLANK=True\n```\n\n"
    },
    {
      "title": "Error \"radeon: Failed to allocate virtual address for buffer:\" when launching GL application",
      "level": 3,
      "content": "This error is given when the power management in the kernel driver is running. You can overcome this error by appending radeon.runpm=0 to the kernel parameters in the bootloader.\n\n"
    },
    {
      "title": "Constant hangs/freezes with Vulkan applications/games using VSync with closed-source drivers and reverse PRIME",
      "level": 3,
      "content": "Some Vulkan applications (particularly ones using VK_PRESENT_MODE_FIFO_KHR and/or VK_PRESENT_MODE_FIFO_RELAXED_KHR, including Windows games ran with DXVK) will cause the GPU to lockup constantly (~5-10 seconds freezed, ~1 second working fine)[11] when ran on a system using reverse PRIME.\n\nA GPU lockup will render any input unusable (this includes switching TTYs and using SysRq functions).\n\nThere is no known fix for this NVIDIA bug, but a few workarounds exist:\n\n- Turning Vsync off (not possible for some applications)\n- Turning PRIME Synchronization[12] off (will introduce screen tearing):\n\n```\nxrandr --output HDMI-0 --set \"PRIME Synchronization\" 0 #replace HDMI-0 with your xrandr output ID\n```\n\nYou can verify if your configuration is affected by the issue simply by running vkcube from the vulkan-tools package.\n\n"
    },
    {
      "title": "Some programs have a delay when opening under Wayland",
      "level": 3,
      "content": "If you have RTD3 working (from #NVIDIA), when using Wayland you will experience some delay when a program opens, this is because it tries to power on the GPU first (which it takes ~1 second or more) and then it tries to open the program, wasting time and battery life. This is an NVIDIA driver problem. More details here\n\nTo solve this, add these 2 lines in your /etc/environment file:\n\n```\n/etc/environment\n```\n\n```\n__EGL_VENDOR_LIBRARY_FILENAMES=/usr/share/glvnd/egl_vendor.d/50_mesa.json\n__GLX_VENDOR_LIBRARY_NAME=mesa\n```\n\n"
    },
    {
      "title": "Error when running Wine games with DXVK",
      "level": 3,
      "content": "When using PRIME offload, encountering the Major opcode of failed request: 156 (NV-GLX) is a known problem. The only known workaround is to start X session entirely on NVIDIA GPU. A user friendly way to switching between NVIDIA only and PRIME offload method is the optimus-manager utility or write some automation scripts yourself.\n\n"
    },
    {
      "title": "See also",
      "level": 2,
      "content": "- Nouveau Optimus\n\n"
    }
  ]
}