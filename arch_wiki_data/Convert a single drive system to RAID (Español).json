{
  "title": "Convert a single drive system to RAID (Español)",
  "url": "https://wiki.archlinux.org/title/Convert_a_single_drive_system_to_RAID_(Espa%C3%B1ol)",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "This guide shows how to convert a functional single-drive system to a RAID 1 setup after adding a second drive, without the need to temporarily store the data on a third drive. The procedure can also be adapted, simplifying it, to the conversion of simple non-root partitions, and to other RAID levels.\n\n"
    },
    {
      "title": "Scenario",
      "level": 2,
      "content": "This example assumes that the pre-existing disk is /dev/sda, which contains only one partition, /dev/sda1, used for the whole system. The newly-added disk is /dev/sdb.\n\n"
    },
    {
      "title": "Partition the disk",
      "level": 3,
      "content": "The first step is creating the partition on the new disk, /dev/sdb1, that will be used as the mirror for the RAID array. In general, in this step it is not needed to recreate the exact partitioning scheme of the pre-existing drive; RAID can even be configured on whole disks, and partitions or logical volumes created later.\n\nMake sure that the partition type is set as FD. See RAID#Prepare the devices and RAID#Partition the devices for more information.\n\n"
    },
    {
      "title": "Create the RAID device",
      "level": 3,
      "content": "Next, create the RAID array in a degraded state, using only the new disk. Note how the missing keyword is specified for the first device: this will be added later.\n\n```\n# mdadm --create /dev/md0 --level=1 --raid-devices=2 missing /dev/device\n```\n\nReplace device with the one you are wanting to use before running the command.\n\nIf you want to use Syslinux, then specify --metadata=1.0 (for the boot partition). As of Syslinux 6.03, mdadm 1.2 is not yet supported in Syslinux. See also Software RAID and LVM.\n\nMake sure the array has been created correctly by checking /proc/mdstat:\n\n```\n# Personalities : [raid1]                                                                                                                                                                       \nmd0 : active raid1 sdb1[1]                                                                                                                                                                    \n      2930034432 blocks super 1.2 [2/1] [_U]                                                                                                                                                  \n      bitmap: 22/22 pages [88KB], 65536KB chunk                                                                                                                                               \n                                                                                                                                                                                              \nunused devices: <none>\n```\n\n"
    },
    {
      "title": "Make file system",
      "level": 3,
      "content": "Create the needed file system on the /dev/md0 device.\n\n"
    },
    {
      "title": "Copy the data on the array",
      "level": 2,
      "content": "Mount the array:\n\n```\n# mount --mkdir /dev/md0 /mnt/new-raid\n```\n\nNow copy the data from /dev/sda1 to /mnt/new-raid/, for example using rsync.\n\n"
    },
    {
      "title": "Update the boot loader",
      "level": 3,
      "content": "Create a new entry in the boot loader to load the system from the RAID array in the new disk.\n\n"
    },
    {
      "title": "GRUB legacy",
      "level": 4,
      "content": "Note: **The factual accuracy of this article or section is disputed.** The factual accuracy of this article or section is disputed.\n\nThe factual accuracy of this article or section is disputed.\n\nUse your preferred text editor to open /mnt/new-raid/boot/grub/menu.lst.\n\n```\n--- SNIP ---\ndefault   0\ncolor light-blue/black light-cyan/blue\n\n## fallback\nfallback 1\n\n# (0) Arch Linux\ntitle  Arch Linux - Original Disc\nroot   (hd0,0)\nkernel /vmlinuz-linux root=/dev/sda1\n\n# (1) Arch Linux\ntitle  Arch Linux - New RAID\nroot   (hd1,0)\n#kernel /vmlinuz-linux root=/dev/sda1 ro\nkernel /vmlinuz-linux root=/dev/md0 md=0,/dev/sda1,/dev/sdb1\n--- SNIP ---\n```\n\nNotice we added the fallback line and duplicated the Arch Linux entry with a different root directive on the kernel line.\n\nAlso update the \"kopt\" and \"groot\" sections, as shown below, if they are in your /mnt/new-raid/boot/grub/menu.lst file, because it will make applying distribution kernel updates easier:\n\n```\n- # kopt=root=UUID=fbafab1a-18f5-4bb9-9e66-a71c1b00977e ro\n+ # kopt=root=/dev/md0 ro md=0,/dev/sda1,/dev/sdb1\n\n## default GRUB root device\n## e.g. groot=(hd0,0)\n- # groot=(hd0,0)\n+ # groot=(hd0,1)\n```\n\nSee GRUB Legacy for more information.\n\n"
    },
    {
      "title": "GRUB",
      "level": 4,
      "content": "Please refer to GRUB#RAID.\n\nTo boot the system from your degraded array, you will need to (1) add the mdadm_udev hook to the HOOKS in /etc/mkinitcpio.conf (after the entry for block) and (2) regenerate the initramfs and generate a new configuration file. You can then add a menu entry in /boot/grub/grub.cfg pointing to the raid partitions for boot. This is complicated by the default generation options making use of a primary boot entry, and placing the remaining boot entries in sub-menus. To restore generation of a single entry per-line for each boot option, simply add:\n\n```\nGRUB_DISABLE_SUBMENU=y\n```\n\nto /etc/default/grub and regenerate grub.cfg. Now you can simply add an entry containing either the device files (e.g. /dev/md0, /dev/md1 or simply use the UUID for each of the raid filesystems. After having done so, the easiest way to add an entry to boot from the degraded arrays is simply to copy the \"Arch Linux, with Linux linux\" entry and change the UUID to match your arrays as shown in /dev/disk/by-uuid.\n\n"
    },
    {
      "title": "Alter fstab",
      "level": 3,
      "content": "You need to tell fstab on the new disk where to find the new device. It is recommended to use Persistent block device naming.\n\n```\n/mnt/new-raid/etc/fstab\n```\n\n```\n/dev/md0    /    ext4     defaults   0 1\n```\n\n"
    },
    {
      "title": "Chroot into the RAID system",
      "level": 4,
      "content": "```\n# mount --bind /sys /mnt/new-raid/sys\n# mount --bind /proc /mnt/new-raid/proc\n# mount --bind /dev /mnt/new-raid/dev\n# chroot /mnt/new-raid/\n```\n\nIf the chroot command gives you an error like chroot: failed to run command `/bin/zsh': No such file or directory, then use chroot /mnt/new-raid/ /bin/bash instead.\n\n"
    },
    {
      "title": "Record mdadm's config",
      "level": 4,
      "content": "Edit /etc/mdadm.conf and change the MAILADDR line to be your email address, if you want emailed alerts of problems with the RAID 1.\n\nThen save the array configuration with UUIDs to make it easier for the system to find /dev/md0 at boot. If you do not do this, you can get an ALERT! /dev/md0 does not exist error when booting:\n\n```\n# mdadm --detail --scan >> /etc/mdadm.conf\n```\n\n"
    },
    {
      "title": "Rebuild initcpio",
      "level": 4,
      "content": "Follow RAID#Configure mkinitcpio.\n\n"
    },
    {
      "title": "Install the boot loader on the RAID array",
      "level": 3,
      "content": "Note: **This article or section needs expansion.** This article or section needs expansion.\n\nThis article or section needs expansion.\n\n"
    },
    {
      "title": "GRUB Legacy",
      "level": 4,
      "content": "Start GRUB:\n\n```\n# grub --no-floppy\n```\n\nThen we find our two partitions - the current one (hd0,0) (I.e. first disk, first partition), and (hd1,1) (i.e. the partition we just added above, on the second partition of the second drive). Check you get two results here:\n\n```\ngrub> find /boot/grub/stage1\n(hd0,0)\n(hd1,1)\n```\n\nThen we tell GRUB to assume the new second drive is (hd0), i.e. the first disk in the system (when it is not currently the case). If your first disk fails, however, and you remove it, or you change the order disks are detected in the BIOS so that you can boot from your second disk, then your second disk will become the first disk in the system. The MBR will then be correct, your new second drive will have become your first drive, and you will be able to boot from this disk.\n\n```\ngrub> device (hd0) /dev/sdb\n```\n\nThen we install GRUB onto the MBR of our new second drive. Check that the \"partition type\" is detected as \"0xfd\", as shown below, to make sure you have the right partition:\n\n```\ngrub> root (hd0,1)\n Filesystem type is ext2fs, partition type 0xfd\ngrub> setup (hd0)\n Checking if \"/boot/grub/stage1\" exists... yes\n Checking if \"/boot/grub/stage2\" exists... yes\n Checking if \"/boot/grub/e2fs_stage1_5\" exists... yes\n Running \"embed /boot/grub/e2fs_stage1_5 (hd0)\"...  16 sectors are embedded. succeeded\n Running \"install /boot/grub/stage1 (hd0) (hd0)1+16 p (hd0,1)/boot/grub/stage2 /boot/grub/grub.conf\"... succeeded\n Done\ngrub> quit\n```\n\n"
    },
    {
      "title": "Verify success",
      "level": 3,
      "content": "Reboot the computer, making sure it boots from the new RAID disk (/dev/sdb) and not the original disk (/dev/sda). You may need to change the boot device priorities in your BIOS to do this.\n\nOnce the boot loader on the new disk loads, make sure you select to boot the new system entry you created earlier.\n\nVerify you have booted from the RAID array by looking at the output of mount. Also check mdstat again only to confirm which disk is in the array.\n\n```\n# mount\n```\n\n```\n/dev/md0 on / type ext4 (rw)\n```\n\nNote: **The factual accuracy of this article or section is disputed.** The factual accuracy of this article or section is disputed.\n\nThe factual accuracy of this article or section is disputed.\n\n```\n# cat /proc/mdstat\n```\n\n```\nPersonalities : [linear] [raid0] [raid1] [raid5] [multipath] [raid6] [raid10]\n md0 : active raid1 sdb1[1]\n      40064 blocks [2/1] [_U]\n \n unused devices: <none>\n```\n\nIf the system boots fine, and the output of the above commands is correct, then you are running off the degraded RAID array, as expected.\n\n"
    },
    {
      "title": "Partition original disk",
      "level": 3,
      "content": "Copy the partition table from /dev/sdb (newly implemented RAID disk) to /dev/sda (second disk we are adding to the array) so that both disks have exactly the same layout:\n\n```\n# sfdisk -d /dev/sdb | sfdisk /dev/sda\n```\n\nAlternative method: this will output the /dev/sdb partition layout to a file, then it is used as input for partitioning /dev/sda.\n\n```\n# sfdisk -d /dev/sdb > raidinfo-partitions.sdb\n# sfdisk /dev/sda < raidinfo-partitions.sdb\n```\n\nVerify that the partitioning is identical:\n\n```\n# fdisk -l\n```\n\n```\nmdadm: /dev/sda1 not large enough to join array\n```\n\n"
    },
    {
      "title": "Add disk partition to array",
      "level": 3,
      "content": "```\n# mdadm /dev/md0 -a /dev/sda1\n```\n\n```\nmdadm: hot added /dev/sda1\n```\n\nVerify that the RAID array is being rebuilt:\n\n```\n# cat /proc/mdstat\n```\n\n```\nPersonalities : [raid1] \nmd0 : active raid1 sda1[2] sdb1[1]\n      2930034432 blocks super 1.2 [2/1] [_U]\n      [>....................]  recovery =  0.2% (5973824/2930034432) finish=332.5min speed=146528K/sec\n      bitmap: 22/22 pages [88KB], 65536KB chunk\n\nunused devices: <none>\n```\n\n"
    },
    {
      "title": "See also",
      "level": 2,
      "content": "- Convert running system to RAID 5 — Example using RAID 5\n\n"
    }
  ]
}