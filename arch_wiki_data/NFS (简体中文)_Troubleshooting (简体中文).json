{
  "title": "NFS (简体中文)/Troubleshooting (简体中文)",
  "url": "https://wiki.archlinux.org/title/NFS_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)/Troubleshooting_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "Related articles\n\n- NFS\n\nNote: **This article or section is out of date.** This article or section is out of date.\n\nThis article or section is out of date.\n\nDedicated article for common problems and solutions.\n\n"
    },
    {
      "title": "exportfs: /etc/exports:2: syntax error: bad option list",
      "level": 3,
      "content": "Make sure to delete all space from the option list in /etc/exports.\n\n"
    },
    {
      "title": "exportfs: requires fsid= for NFS export",
      "level": 3,
      "content": "As not all filesystems are stored on devices and not all filesystems have UUIDs (e.g. FUSE), it is sometimes necessary to explicitly tell NFS how to identify a filesystem. This is done with the fsid option:\n\n```\n/etc/exports\n```\n\n```\n/srv/nfs client(rw,sync,crossmnt,fsid=0)\n/srv/nfs/music client(rw,sync,fsid=10)\n```\n\n"
    },
    {
      "title": "Group/GID permissions issues",
      "level": 3,
      "content": "If NFS shares mount fine, and are fully accessible to the owner, but not to group members; check the number of groups that user belongs to. NFS has a limit of 16 on the number of groups a user can belong to. If you have users with more than this, you need to enable the manage-gids start-up flag on the NFS server:\n\n```\n/etc/nfs.conf\n```\n\n```\n[mountd]\nmanage-gids=y\n```\n\n"
    },
    {
      "title": "\"Permission denied\" when trying to write files as root",
      "level": 3,
      "content": "- If you need to mount shares as root, and have full r/w access from the client, add the no_root_squash option to the export in /etc/exports:\n\n```\n/var/cache/pacman/pkg 192.168.1.0/24(rw,no_subtree_check,no_root_squash)\n```\n\n- You must also add no_root_squash to the first line in /etc/exports:\n\n```\n/ 192.168.1.0/24(rw,fsid=root,no_root_squash,no_subtree_check)\n```\n\n"
    },
    {
      "title": "\"RPC: Program not registered\" when showmount -e command issued",
      "level": 3,
      "content": "Make sure that nfs-server.service and rpcbind.service are running on the server site, see systemd. If they are not, start and enable them.\n\nAlso make sure NFSv3 is enabled. showmount does not work with NFSv4-only servers.\n\n"
    },
    {
      "title": "UDP mounts not working",
      "level": 3,
      "content": "nfs-utils disabled serving NFS over UDP in version 2.2.1. Arch core updated to 2.3.1 on 21 Dec 2017 (skipping over 2.2.1.) If UDP stopped working then, add udp=y under [nfsd] in /etc/nfs.conf. Then restart nfs-server.service.\n\n"
    },
    {
      "title": "Timeout with big directories",
      "level": 3,
      "content": "Since nfs-utils version 1.0.x, every subdirectory is checked for permissions. This can lead to timeout on directories with a \"large\" number of subdirectories, even a few hundreds.\n\nTo disable this behaviour, add the option no_subtree_check to /etc/exports to the share directory.\n\n"
    },
    {
      "title": "mount.nfs4: No such device",
      "level": 3,
      "content": "Make sure the nfsd kernel module has been loaded.\n\n"
    },
    {
      "title": "mount.nfs4: Invalid argument",
      "level": 3,
      "content": "Enable and start nfs-client.target and make sure the appropriate daemons (nfs-idmapd, rpc-gssd, etc) are running on the server.\n\n"
    },
    {
      "title": "mount.nfs4: Network is unreachable",
      "level": 3,
      "content": "Users making use of systemd-networkd or NetworkManager might notice NFS mounts are not mounted when booting.\n\nForce the network to be completely configured by enabling systemd-networkd-wait-online.service or NetworkManager-wait-online.service. This may slow down the boot-process because fewer services run in parallel.\n\n"
    },
    {
      "title": "mount.nfs4: an incorrect mount option was specified",
      "level": 3,
      "content": "This can happen if using the sec=krb5 option without nfs-client.target and/or rpc-gssd.service running. Starting and enabling those services should resolve the issue.\n\n"
    },
    {
      "title": "Unable to connect from OS X clients",
      "level": 3,
      "content": "When trying to connect from an OS X client, you will see that everything is ok in the server logs, but OS X will refuse to mount your NFS share. You can do one of two things to fix this:\n\n- On the NFS server, add the insecure option to the share in /etc/exports and re-run exportfs -r.\n\n... OR ...\n\n- On the OS X client, add the resvport option to the mount command line. You can also set resvport as a default client mount option in /etc/nfs.conf:\n\n```\n/etc/nfs.conf\n```\n\n```\nnfs.client.mount.options = resvport\n```\n\nUsing the default client mount option should also affect mounting the share from Finder via \"Connect to Server...\".\n\n"
    },
    {
      "title": "Unreliable connection from OS X clients",
      "level": 3,
      "content": "OS X's NFS client is optimized for OS X Servers and might present some issues with Linux servers. If you are experiencing slow performance, frequent disconnects and problems with international characters edit the default mount options by adding the line nfs.client.mount.options = intr,locallocks,nfc to /etc/nfs.conf on your Mac client. More information about the mount options can be found in the OS X mount_nfs(8).\n\n"
    },
    {
      "title": "Intermittent client freezes when copying large files",
      "level": 3,
      "content": "If you copy large files from your client machine to the NFS server, the transfer speed is very fast, but after some seconds the speed drops and your client machine intermittently locks up completely for some time until the transfer is finished.\n\nTry adding sync as a mount option on the client (e.g. in /etc/fstab) to fix this problem.\n\n"
    },
    {
      "title": "NFSv4",
      "level": 4,
      "content": "If you use Kerberos (sec=krb5*), make sure the client and server clocks are correct. Using ntpd or systemd-timesyncd is recommended. Also, check that the canonical name for the server as resolved on the client (see Domain name resolution) matches the name in the server's NFS principal.\n\n"
    },
    {
      "title": "NFSv3 and earlier",
      "level": 4,
      "content": "nfs-utils versions 1.2.1-2 or higher use NFSv4 by default, resulting in NFSv3 shares failing on upgrade. The problem can be solved by using either mount option 'vers=3' or 'nfsvers=3' on the command line:\n\n```\n# mount.nfs remote target directory -o ...,vers=3,...\n# mount.nfs remote target directory -o ...,nfsvers=3,...\n```\n\nor in /etc/fstab:\n\n```\nremote target directory nfs ...,vers=3,... 0 0\nremote target directory nfs ...,nfsvers=3,... 0 0\n```\n\n"
    },
    {
      "title": "mount.nfs: Protocol not supported",
      "level": 3,
      "content": "This error occurs when you include the export root in the path of the NFS source. For example:\n\n```\n# mount SERVER:/srv/nfs4/media /mnt\nmount.nfs4: Protocol not supported\n```\n\nUse the relative path instead:\n\n```\n# mount SERVER:/media /mnt\n```\n\n"
    },
    {
      "title": "Permissions issues",
      "level": 3,
      "content": "If you find that you cannot set the permissions on files properly, make sure the user/user group are both on the client and server.\n\nIf all your files are owned by nobody, and you are using NFSv4, on both the client and server, you should ensure that the nfs-idmapd.service has been started.\n\nOn some systems detecting the domain from FQDN minus hostname does not seem to work reliably. If files are still showing as nobody after the above changes, edit /etc/idmapd.conf, ensure that Domain is set to FQDN minus hostname. For example:\n\n```\n/etc/idmapd.conf\n```\n\n```\n[General]\nDomain = domain.ext\n\n[Mapping]\n\nNobody-User = nobody\nNobody-Group = nobody\n\n[Translation]\n\nMethod = nsswitch\n```\n\n"
    },
    {
      "title": "Problems with Vagrant and synced_folders",
      "level": 3,
      "content": "If you get an error about unuspported protocol, you need to enable NFS over UDP on your host (or make Vagrant use NFS over TCP.) See #UDP mounts not working.\n\nIf Vagrant scripts are unable to mount folders over NFS, installing the net-tools package may solve the issue.\n\n"
    },
    {
      "title": "Performance issues",
      "level": 2,
      "content": "This NFS Howto page has some useful information regarding performance. Here are some further tips:\n\n"
    },
    {
      "title": "Diagnose the problem",
      "level": 3,
      "content": "- Htop should be your first port of call. The most obvious symptom will be a maxed-out CPU.\n- Press F2, and under \"Display options\", enable \"Detailed CPU time\". Press F1 for an explanation of the colours used in the CPU bars. In particular, is the CPU spending most of its time responding to IRQs, or in Wait-IO (wio)?\n\n"
    },
    {
      "title": "Close-to-open/flush-on-close",
      "level": 3,
      "content": "Symptoms: Your clients are writing many small files. The server CPU is not maxed out, but there is very high wait-IO, and the server disk seems to be churning more than you might expect.\n\nIn order to ensure data consistency across clients, the NFS protocol requires that the client's cache is flushed (all data is pushed to the server) whenever a file is closed after writing. Because the server is not allowed to buffer disk writes (if it crashes, the client will not realise the data was not written properly), the data is written to disk immediately before the client's request is completed. When you are writing lots of small files from the client, this means that the server spends most of its time waiting for small files to be written to its disk, which can cause a significant reduction in throughput.\n\nSee this excellent article or the nfs manpage for more details on the close-to-open policy. There are several approaches to solving this problem:\n\n"
    },
    {
      "title": "The nocto mount option",
      "level": 4,
      "content": "If all of the following conditions are satisfied:\n\n- The export you have mounted on the client is only going to be used by the one client.\n- It does not matter too much if a file written on one client does not immediately appear on other clients.\n- It does not matter if after a client has written a file, and the client thinks the file has been saved, and then the client crashes, the file may be lost.\n\nUse the nocto mount option, which will disable the close-to-open behavior.\n\n"
    },
    {
      "title": "The async export option",
      "level": 4,
      "content": "Does your situation match these conditions?\n\n- It is important that when a file is closed after writing on one client, it is: Immediately visible on all the other clients. Safely stored on the server, even if the client crashes immediately after closing the file.\n- It is not important to you that if the server crashes: You may lose the files that were most recently written by clients. When the server is restarted, the clients will believe their recent files exist, even though they were actually lost.\n\n- Immediately visible on all the other clients.\n- Safely stored on the server, even if the client crashes immediately after closing the file.\n\n- You may lose the files that were most recently written by clients.\n- When the server is restarted, the clients will believe their recent files exist, even though they were actually lost.\n\nIn this situation, you can use async instead of sync in the server's /etc/exports file for those specific exports. See the exports manual page for details. In this case, it does not make sense to use the nocto mount option on the client.\n\n"
    },
    {
      "title": "Buffer cache size and MTU",
      "level": 3,
      "content": "Symptoms: High kernel or IRQ CPU usage, a very high packet count through the network card.\n\nThis is a trickier optimisation. Make sure this is definitely the problem before spending too much time on this. The default values are usually fine for most situations.\n\nSee this article for information about I/O buffering in NFS. Essentially, data is accumulated into buffers before being sent. The size of the buffer will affect the way data is transmitted over the network. The Maximum Transmission Unit (MTU) of the network equipment will also affect throughput, as the buffers need to be split into MTU-sized chunks before they are sent over the network. If your buffer size is too big, the kernel or hardware may spend too much time splitting it into MTU-sized chunks. If the buffer size is too small, there will be overhead involved in sending a very large number of small packets. You can use the rsize and wsize mount options on the client to alter the buffer cache size. To achieve the best throughput, you need to experiment and discover the best values for your setup.\n\nIt is possible to change the MTU of many network cards. If your clients are on a separate subnet (e.g. for a Beowulf cluster), it may be safe to configure all of the network cards to use a high MTU. This should be done in very-high-bandwidth environments.\n\nSee NFS#Performance tuning for more information.\n\n"
    },
    {
      "title": "Using rpcdebug",
      "level": 3,
      "content": "Using rpcdebug is the easiest way to manipulate the kernel interfaces in place of echoing bitmasks to /proc.\n\nTable content:\nOption | Description\n-c | Clear the given debug flags\n-s | Set the given debug flags\n-m module | Specify which module's flags to set or clear.\n-v | Increase the verbosity of rpcdebug's output\n-h | Print a help message and exit. When combined with the -v option, also prints the available debug flags.\n\nFor the -m option, the available modules are:\n\nTable content:\nModule | Description\nnfsd | The NFS server\nnfs | The NFS client\nnlm | The Network Lock Manager, in either an NFS client or server\nrpc | The Remote Procedure Call module, in either an NFS client or server\n\nExamples:\n\n```\nrpcdebug -m rpc -s all    # sets all debug flags for RPC\nrpcdebug -m rpc -c all    # clears all debug flags for RPC\n\nrpcdebug -m nfsd -s all   # sets all debug flags for NFS Server\nrpcdebug -m nfsd -c all   # clears all debug flags for NFS Server\n```\n\nOnce the flags are set you can tail the journal for the debug output, usually by running journalctl -fl as root or similar.\n\n"
    },
    {
      "title": "Using mountstats",
      "level": 3,
      "content": "The nfs-utils package contains the mountstats tool, which can retrieve a lot of statistics about NFS mounts, including average timings and packet size.\n\n```\n$ mountstats \nStats for example:/tank mounted on /tank:\n  NFS mount options: rw,sync,vers=4.2,rsize=524288,wsize=524288,namlen=255,acregmin=3,acregmax=60,acdirmin=30,acdirmax=60,soft,proto=tcp,port=0,timeo=15,retrans=2,sec=sys,clientaddr=xx.yy.zz.tt,local_lock=none\n  NFS server capabilities: caps=0xfbffdf,wtmult=512,dtsize=32768,bsize=0,namlen=255\n  NFSv4 capability flags: bm0=0xfdffbfff,bm1=0x40f9be3e,bm2=0x803,acl=0x3,sessions,pnfs=notconfigured\n  NFS security flavor: 1  pseudoflavor: 0\n\nNFS byte counts:\n  applications read 248542089 bytes via read(2)\n  applications wrote 0 bytes via write(2)\n  applications read 0 bytes via O_DIRECT read(2)\n  applications wrote 0 bytes via O_DIRECT write(2)\n  client read 171375125 bytes via NFS READ\n  client wrote 0 bytes via NFS WRITE\n\nRPC statistics:\n  699 RPC requests sent, 699 RPC replies received (0 XIDs not found)\n  average backlog queue length: 0\n\nREAD:\n\t338 ops (48%) \n\tavg bytes sent per op: 216\tavg bytes received per op: 507131\n\tbacklog wait: 0.005917 \tRTT: 548.736686 \ttotal execute time: 548.775148 (milliseconds)\nGETATTR:\n\t115 ops (16%) \n\tavg bytes sent per op: 199\tavg bytes received per op: 240\n\tbacklog wait: 0.008696 \tRTT: 15.756522 \ttotal execute time: 15.843478 (milliseconds)\nACCESS:\n\t93 ops (13%) \n\tavg bytes sent per op: 203\tavg bytes received per op: 168\n\tbacklog wait: 0.010753 \tRTT: 2.967742 \ttotal execute time: 3.032258 (milliseconds)\nLOOKUP:\n\t32 ops (4%) \n\tavg bytes sent per op: 220\tavg bytes received per op: 274\n\tbacklog wait: 0.000000 \tRTT: 3.906250 \ttotal execute time: 3.968750 (milliseconds)\nOPEN_NOATTR:\n\t25 ops (3%) \n\tavg bytes sent per op: 268\tavg bytes received per op: 350\n\tbacklog wait: 0.000000 \tRTT: 2.320000 \ttotal execute time: 2.360000 (milliseconds)\nCLOSE:\n\t24 ops (3%) \n\tavg bytes sent per op: 224\tavg bytes received per op: 176\n\tbacklog wait: 0.000000 \tRTT: 30.250000 \ttotal execute time: 30.291667 (milliseconds)\nDELEGRETURN:\n\t23 ops (3%) \n\tavg bytes sent per op: 220\tavg bytes received per op: 160\n\tbacklog wait: 0.000000 \tRTT: 6.782609 \ttotal execute time: 6.826087 (milliseconds)\nREADDIR:\n\t4 ops (0%) \n\tavg bytes sent per op: 224\tavg bytes received per op: 14372\n\tbacklog wait: 0.000000 \tRTT: 198.000000 \ttotal execute time: 198.250000 (milliseconds)\nSERVER_CAPS:\n\t2 ops (0%) \n\tavg bytes sent per op: 172\tavg bytes received per op: 164\n\tbacklog wait: 0.000000 \tRTT: 1.500000 \ttotal execute time: 1.500000 (milliseconds)\nFSINFO:\n\t1 ops (0%) \n\tavg bytes sent per op: 172\tavg bytes received per op: 164\n\tbacklog wait: 0.000000 \tRTT: 2.000000 \ttotal execute time: 2.000000 (milliseconds)\nPATHCONF:\n\t1 ops (0%) \n\tavg bytes sent per op: 164\tavg bytes received per op: 116\n\tbacklog wait: 0.000000 \tRTT: 1.000000 \ttotal execute time: 1.000000 (milliseconds)\n```\n\n"
    },
    {
      "title": "Kernel Interfaces",
      "level": 3,
      "content": "A bitmask of the debug flags can be echoed into the interface to enable output to syslog; 0 is the default:\n\n```\n/proc/sys/sunrpc/nfsd_debug\n/proc/sys/sunrpc/nfs_debug\n/proc/sys/sunrpc/nlm_debug\n/proc/sys/sunrpc/rpc_debug\n```\n\nSysctl controls are registered for these interfaces, so they can be used instead of echo:\n\n```\nsysctl -w sunrpc.rpc_debug=1023\nsysctl -w sunrpc.rpc_debug=0\n\nsysctl -w sunrpc.nfsd_debug=1023\nsysctl -w sunrpc.nfsd_debug=0\n```\n\nAt runtime the server holds information that can be examined:\n\n```\ngrep . /proc/net/rpc/*/content\ncat /proc/fs/nfs/exports\ncat /proc/net/rpc/nfsd\nls -l /proc/fs/nfsd\n```\n\nA rundown of /proc/net/rpc/nfsd (the userspace tool nfsstat pretty-prints this info):\n\n```\n* rc (reply cache): <hits> <misses> <nocache>\n- hits: client it's retransmitting\n- misses: a operation that requires caching\n- nocache: a operation that no requires caching\n\n* fh (filehandle): <stale> <total-lookups> <anonlookups> <dir-not-in-cache> <nodir-not-in-cache>\n- stale: file handle errors\n- total-lookups, anonlookups, dir-not-in-cache, nodir-not-in-cache\n  . always seem to be zeros\n\n* io (input/output): <bytes-read> <bytes-written>\n- bytes-read: bytes read directly from disk\n- bytes-written: bytes written to disk\n\n* th (threads): <threads> <fullcnt> <10%-20%> <20%-30%> ... <90%-100%> <100%>\n  DEPRECATED:  All fields after <threads> are hard-coded to 0\n- threads: number of nfsd threads\n- fullcnt: number of times that the last 10% of threads are busy\n- 10%-20%, 20%-30% ... 90%-100%: 10 numbers representing 10-20%, 20-30% to 100%\n  . Counts the number of times a given interval are busy\n\n* ra (read-ahead): <cache-size> <10%> <20%> ... <100%> <not-found>\n- cache-size: always the double of number threads\n- 10%, 20% ... 100%: how deep it found what was looking for\n- not-found: not found in the read-ahead cache\n\n* net: <netcnt> <netudpcnt> <nettcpcnt> <nettcpconn>\n- netcnt: counts every read\n- netudpcnt: counts every UDP packet it receives\n- nettcpcnt: counts every time it receives data from a TCP connection\n- nettcpconn: count every TCP connection it receives\n\n* rpc: <rpccnt> <rpcbadfmt+rpcbadauth+rpcbadclnt> <rpcbadfmt> <rpcbadauth> <rpcbadclnt>\n- rpccnt: counts all rpc operations\n- rpcbadfmt: counts if while processing a RPC it encounters the following errors:\n  . err_bad_dir, err_bad_rpc, err_bad_prog, err_bad_vers, err_bad_proc, err_bad\n- rpcbadauth: bad authentication\n  . does not count if you try to mount from a machine that it's not in your exports file\n- rpcbadclnt: unused\n\n* procN (N = vers): <vs_nproc> <null> <getattr> <setattr> <lookup> <access> <readlink> <read> <write> <create> <mkdir> <symlink> <mknod> <remove> <rmdir> <rename> <link> <readdir> <readdirplus> <fsstat> <fsinfo> <pathconf> <commit>\n- vs_nproc: number of procedures for NFS version\n  . v2: nfsproc.c, 18\n  . v3: nfs3proc.c, 22\n  - v4, nfs4proc.c, 2\n- statistics: generated from NFS operations at runtime\n\n* proc4ops: <ops> <x..y>\n- ops: the definition of LAST_NFS4_OP, OP_RELEASE_LOCKOWNER = 39, plus 1 (so 40); defined in nfs4.h\n- x..y: the array of nfs_opcount up to LAST_NFS4_OP (nfsdstats.nfs4_opcount[i])\n```\n\n"
    },
    {
      "title": "NFSD debug flags",
      "level": 3,
      "content": "```\n/usr/include/linux/nfsd/debug.h\n```\n\n```\n/*\n * knfsd debug flags\n */\n#define NFSDDBG_SOCK            0x0001\n#define NFSDDBG_FH              0x0002\n#define NFSDDBG_EXPORT          0x0004\n#define NFSDDBG_SVC             0x0008\n#define NFSDDBG_PROC            0x0010\n#define NFSDDBG_FILEOP          0x0020\n#define NFSDDBG_AUTH            0x0040\n#define NFSDDBG_REPCACHE        0x0080\n#define NFSDDBG_XDR             0x0100\n#define NFSDDBG_LOCKD           0x0200\n#define NFSDDBG_ALL             0x7FFF\n#define NFSDDBG_NOCHANGE        0xFFFF\n```\n\n"
    },
    {
      "title": "NFS debug flags",
      "level": 3,
      "content": "```\n/usr/include/linux/nfs_fs.h\n```\n\n```\n/*\n * NFS debug flags\n */\n#define NFSDBG_VFS              0x0001\n#define NFSDBG_DIRCACHE         0x0002\n#define NFSDBG_LOOKUPCACHE      0x0004\n#define NFSDBG_PAGECACHE        0x0008\n#define NFSDBG_PROC             0x0010\n#define NFSDBG_XDR              0x0020\n#define NFSDBG_FILE             0x0040\n#define NFSDBG_ROOT             0x0080\n#define NFSDBG_CALLBACK         0x0100\n#define NFSDBG_CLIENT           0x0200\n#define NFSDBG_MOUNT            0x0400\n#define NFSDBG_FSCACHE          0x0800\n#define NFSDBG_PNFS             0x1000\n#define NFSDBG_PNFS_LD          0x2000\n#define NFSDBG_STATE            0x4000\n#define NFSDBG_ALL              0xFFFF\n```\n\n"
    },
    {
      "title": "NLM debug flags",
      "level": 3,
      "content": "```\n/usr/include/linux/lockd/debug.h\n```\n\n```\n/*\n * Debug flags\n */\n#define NLMDBG_SVC\t\t0x0001\n#define NLMDBG_CLIENT\t\t0x0002\n#define NLMDBG_CLNTLOCK\t\t0x0004\n#define NLMDBG_SVCLOCK\t\t0x0008\n#define NLMDBG_MONITOR\t\t0x0010\n#define NLMDBG_CLNTSUBS\t\t0x0020\n#define NLMDBG_SVCSUBS\t\t0x0040\n#define NLMDBG_HOSTCACHE\t0x0080\n#define NLMDBG_XDR\t\t0x0100\n#define NLMDBG_ALL\t\t0x7fff\n```\n\n"
    },
    {
      "title": "RPC debug flags",
      "level": 3,
      "content": "```\n/usr/include/linux/sunrpc/debug.h\n```\n\n```\n/*\n * RPC debug facilities\n */\n#define RPCDBG_XPRT             0x0001\n#define RPCDBG_CALL             0x0002\n#define RPCDBG_DEBUG            0x0004\n#define RPCDBG_NFS              0x0008\n#define RPCDBG_AUTH             0x0010\n#define RPCDBG_BIND             0x0020\n#define RPCDBG_SCHED            0x0040\n#define RPCDBG_TRANS            0x0080\n#define RPCDBG_SVCXPRT          0x0100\n#define RPCDBG_SVCDSP           0x0200\n#define RPCDBG_MISC             0x0400\n#define RPCDBG_CACHE            0x0800\n#define RPCDBG_ALL              0x7fff\n```\n\n"
    },
    {
      "title": "See also",
      "level": 3,
      "content": "- rpcdebug(8)\n- http://utcc.utoronto.ca/~cks/space/blog/linux/NFSClientDebuggingBits\n- http://www.novell.com/support/kb/doc.php?id=7011571\n- http://stromberg.dnsalias.org/~strombrg/NFS-troubleshooting-2.html\n- https://lore.kernel.org/linux-nfs/471D17F8.5060709@cesca.es/\n\n"
    }
  ]
}