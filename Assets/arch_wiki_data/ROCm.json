{
  "title": "ROCm",
  "url": "https://wiki.archlinux.org/title/ROCm",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "Related articles\n\n- Nvidia\n- Hardware video acceleration\n\nGPGPU stands for General-purpose computing on graphics processing units.\n\n"
    },
    {
      "title": "OpenCL",
      "level": 2,
      "content": "OpenCL (Open Computing Language) is an open, royalty-free parallel programming specification developed by the Khronos Group, a non-profit consortium.\n\nThe OpenCL specification describes a programming language, a general environment that is required to be present, and a C API to enable programmers to call into this environment.\n\n"
    },
    {
      "title": "Runtime",
      "level": 3,
      "content": "To execute programs that use OpenCL, a compatible hardware runtime needs to be installed.\n\n"
    },
    {
      "title": "AMD/ATI",
      "level": 4,
      "content": "- opencl-rusticl-mesa: OpenCL support with rusticl for mesa drivers\n- rocm-opencl-runtime: Part of AMD's ROCm GPU compute stack, officially supporting a small range of GPU models (other cards may work with unofficial or partial support). To support cards older than Vega, you need to set the runtime variable ROC_ENABLE_PRE_VEGA=1. This is similar, but not quite equivalent to specifying opencl=rocr in ubuntu's amdgpu-install, because this package's rocm version differs from ubuntu's installer version.\n- opencl-legacy-amdgpu-proAUR: Legacy Orca OpenCL repackaged from AMD's ubuntu releases. Equivalent to specifying opencl=legacy in ubuntu's amdgpu-install.\n- opencl-amdAUR, opencl-amd-devAUR: ROCm components repackaged from AMD's Ubuntu releases. Equivalent to specifying opencl=rocr,legacy in ubuntu's amdgpu-install.\n- amdapp-sdkAUR: AMD CPU runtime\n\n"
    },
    {
      "title": "NVIDIA",
      "level": 4,
      "content": "- opencl-rusticl-mesa: OpenCL support with rusticl for mesa drivers\n- opencl-nvidia: official NVIDIA runtime\n\n"
    },
    {
      "title": "Intel",
      "level": 4,
      "content": "- intel-compute-runtime: a.k.a. the Neo OpenCL runtime, the open-source implementation for Intel HD Graphics GPU on Gen12 (Alder Lake) and beyond.\n- intel-compute-runtime-legacyAUR: same as above only for Gen11(Rocket Lake) and lower\n- opencl-rusticl-mesa: OpenCL support with rusticl for mesa drivers\n- beignetAUR: the open-source implementation for Intel HD Graphics GPU on Gen7 (Ivy Bridge) and beyond, deprecated by Intel in favour of NEO OpenCL driver, remains recommended solution for legacy hardware platforms (e.g. Ivy Bridge, Haswell).\n- intel-openclAUR: the proprietary implementation for Intel HD Graphics GPU on Gen7 (Ivy Bridge) and beyond, deprecated by Intel in favour of NEO OpenCL driver, remains recommended solution for legacy hardware platforms (e.g. Ivy Bridge, Haswell).\n- intel-opencl-runtimeAUR: the implementation for Intel Core and Xeon processors. It also supports non-Intel CPUs.\n\n"
    },
    {
      "title": "Others",
      "level": 4,
      "content": "- opencl-clover-mesa: OpenCL support with clover for mesa drivers (deprecated, see [1])\n- pocl: LLVM-based OpenCL implementation (hardware independent)\n\nThere is compiler and translator enable OpenCL applications to be run over a Vulkan run-time.\n\n- clspv-gitAUR: Clspv is a prototype compiler for a subset of OpenCL C to Vulkan compute shaders.\n- clvk-gitAUR: clvk is a prototype implementation of OpenCL 3.0 on top of Vulkan using clspv as the compiler.\n- xrt-binAUR: Xilinx Run Time for FPGA xrt\n- fpga-runtime-for-opencl:FPGA Runtime\n\n"
    },
    {
      "title": "32-bit runtime",
      "level": 3,
      "content": "To execute 32-bit programs that use OpenCL, a compatible hardware 32-bit runtime needs to be installed.\n\n"
    },
    {
      "title": "AMD/ATI",
      "level": 4,
      "content": "- lib32-opencl-clover-mesa or lib32-opencl-rusticl-mesa: OpenCL support for AMD/ATI Radeon mesa drivers (32-bit)\n\n"
    },
    {
      "title": "NVIDIA",
      "level": 4,
      "content": "- lib32-opencl-nvidia: OpenCL implemention for NVIDIA (32-bit)\n\n"
    },
    {
      "title": "ICD loader (libOpenCL.so)",
      "level": 3,
      "content": "The OpenCL ICD loader is supposed to be a platform-agnostic library that provides the means to load device-specific drivers through the OpenCL API. Most OpenCL vendors provide their own implementation of an OpenCL ICD loader, and these should all work with the other vendors' OpenCL implementations. Unfortunately, most vendors do not provide completely up-to-date ICD loaders, and therefore Arch Linux has decided to provide this library from a separate project (ocl-icd) which currently provides a functioning implementation of the current OpenCL API.\n\nThe other ICD loader libraries are installed as part of each vendor's SDK. If you want to ensure the ICD loader from the ocl-icd package is used, you can create a file in /etc/ld.so.conf.d which adds /usr/lib to the dynamic program loader's search directories:\n\n```\n/etc/ld.so.conf.d/00-usrlib.conf\n```\n\n```\n/usr/lib\n```\n\nThis is necessary because all the SDKs add their runtime's lib directories to the search path through ld.so.conf.d files.\n\nThe available packages containing various OpenCL ICDs are:\n\n- ocl-icd: recommended, most up-to-date\n- intel-openclAUR by Intel. Provides OpenCL 2.0, deprecated in favour of intel-compute-runtime.\n\n"
    },
    {
      "title": "Development",
      "level": 3,
      "content": "For OpenCL development, the bare minimum additional packages required, are:\n\n- ocl-icd: OpenCL ICD loader implementation, up to date with the latest OpenCL specification.\n- opencl-headers: OpenCL C/C++ API headers.\n\nThe vendors' SDKs provide a multitude of tools and support libraries:\n\n- intel-opencl-sdkAUR: Intel OpenCL SDK (old version, new OpenCL SDKs are included in the INDE and Intel Media Server Studio)\n- amdapp-sdkAUR: This package is installed as /opt/AMDAPP and apart from SDK files it also contains a number of code samples (/opt/AMDAPP/SDK/samples/). It also provides the clinfo utility which lists OpenCL platforms and devices present in the system and displays detailed information about them. As the SDK itself contains a CPU OpenCL driver, no extra driver is needed to execute OpenCL on CPU devices (regardless of its vendor).\n- cuda: Nvidia's GPU SDK which includes support for OpenCL 3.0.\n\n"
    },
    {
      "title": "Implementations",
      "level": 3,
      "content": "To see which OpenCL implementations are currently active on your system, use the following command:\n\n```\n$ ls /etc/OpenCL/vendors\n```\n\nTo find out all possible (known) properties of the OpenCL platform and devices available on the system, install clinfo.\n\nYou can specify which implementations should your application see using ocl-icd-chooseAUR. For example:\n\n```\n$ ocl-icd-choose amdocl64.icd:mesa.icd davinci-resolve-checker\n```\n\n"
    },
    {
      "title": "Rusticl",
      "level": 4,
      "content": "Note: **The factual accuracy of this article or section is disputed.** The factual accuracy of this article or section is disputed.\n\nThe factual accuracy of this article or section is disputed.\n\nRusticl is a new OpenCL implementation written in Rust provided by opencl-rusticl-mesa. It can be enabled by using the environment variable RUSTICL_ENABLE=driver, where driver is a Gallium driver, such as radeonsi or iris.\n\nOptionally, if OpenCL applications still do not detect Rusticl, use the following environment variable:\n\n```\nOCL_ICD_VENDORS=/etc/OpenCL/vendors/rusticl.icd\n```\n\n"
    },
    {
      "title": "Language bindings",
      "level": 4,
      "content": "- JavaScript/HTML5: WebCL\n- Python: python-pyopencl\n- D: cl4d or DCompute\n- Java: Aparapi or JOCL (a part of JogAmp)\n- Mono/.NET: Open Toolkit\n- Go: OpenCL bindings for Go\n- Racket: Racket has a native interface on PLaneT that can be installed via raco.\n- Rust: ocl\n- Julia: OpenCL.jl\n\n"
    },
    {
      "title": "SYCL",
      "level": 2,
      "content": "According to Wikipedia:SYCL:\n\n"
    },
    {
      "title": "Implementations",
      "level": 3,
      "content": "- computecppAUR Codeplay's proprietary implementation of SYCL 1.2.1. Can target SPIR, SPIR-V and experimentally PTX (NVIDIA) as device targets (ends of support on 1st september 2023, will get merged into intel llvm implementation Source).\n- trisycl-gitAUR: Open source implementation mainly driven by Xilinx.\n- hipsycl-cuda-gitAUR and hipsycl-rocm-gitAUR: AdaptiveCpp, implementation of SYCL and C++ standard parallelism for CPUs and GPUs from all vendors, renamed from AMD's hipSYCL.\n- intel-oneapi-dpcpp-cpp: Intel's Data Parallel C++: the oneAPI Implementation of SYCL.\n\n"
    },
    {
      "title": "Checking for SPIR support",
      "level": 3,
      "content": "Most SYCL implementations are able to compile the accelerator code to SPIR or SPIR-V. Both are intermediate languages designed by Khronos that can be consumed by an OpenCL driver. To check whether SPIR or SPIR-V are supported clinfo can be used:\n\n```\n$ clinfo | grep -i spir\n```\n\n```\nPlatform Extensions                             cl_khr_icd cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_depth_images cl_khr_3d_image_writes cl_intel_exec_by_local_thread cl_khr_spir cl_khr_fp64 cl_khr_image2d_from_buffer cl_intel_vec_len_hint \n  IL version                                    SPIR-V_1.0\n  SPIR versions                                 1.2\n```\n\nComputeCpp additionally ships with a tool that summarizes the relevant system information:\n\n```\n$ computecpp_info\n```\n\n```\nDevice 0:\n\n  Device is supported                     : UNTESTED - Untested OS\n  CL_DEVICE_NAME                          : Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz\n  CL_DEVICE_VENDOR                        : Intel(R) Corporation\n  CL_DRIVER_VERSION                       : 18.1.0.0920\n  CL_DEVICE_TYPE                          : CL_DEVICE_TYPE_CPU\n```\n\nNote: **This article or section is out of date.** This article or section is out of date.\n\nThis article or section is out of date.\n\nDrivers known to at least partially support SPIR or SPIR-V include intel-compute-runtime, intel-opencl-runtimeAUR, pocl and amdgpu-pro-openclAUR[broken link: package not found].\n\n"
    },
    {
      "title": "Development",
      "level": 3,
      "content": "SYCL requires a working C++11 environment to be set up. There are a few open source libraries available:\n\n- ComputeCpp SDK: Collection of code examples, cmake integration for ComputeCpp\n- SYCL-DNN: Neural network performance primitives\n- SYCL-BLAS: Linear algebra performance primitives\n- VisionCpp: Computer Vision library\n- SYCL Parallel STL: GPU implementation of the C++17 parallel algorithms\n\n"
    },
    {
      "title": "CUDA",
      "level": 2,
      "content": "CUDA (Compute Unified Device Architecture) is NVIDIA's proprietary, closed-source parallel computing architecture and framework. It requires an NVIDIA GPU, and consists of several components:\n\n- Required: Proprietary NVIDIA kernel module CUDA \"driver\" and \"runtime\" libraries\n- Optional: Additional libraries: CUBLAS, CUFFT, CUSPARSE, etc. CUDA toolkit, including the nvcc compiler CUDA SDK, which contains many code samples and examples of CUDA and OpenCL programs\n\n- Proprietary NVIDIA kernel module\n- CUDA \"driver\" and \"runtime\" libraries\n\n- Additional libraries: CUBLAS, CUFFT, CUSPARSE, etc.\n- CUDA toolkit, including the nvcc compiler\n- CUDA SDK, which contains many code samples and examples of CUDA and OpenCL programs\n\nThe kernel module and CUDA \"driver\" library are shipped in nvidia and opencl-nvidia. The \"runtime\" library and the rest of the CUDA toolkit are available in cuda. cuda-gdb needs ncurses5-compat-libsAUR to be installed, see FS#46598.\n\n"
    },
    {
      "title": "Development",
      "level": 3,
      "content": "The cuda package installs all components in the directory /opt/cuda. The script in /etc/profile.d/cuda.sh sets the relevant environment variables so all build systems that support CUDA can find it.\n\nTo find whether the installation was successful and whether CUDA is up and running, you can compile the CUDA samples. One way to check the installation is to run the deviceQuery sample.\n\n"
    },
    {
      "title": "Language bindings",
      "level": 3,
      "content": "- Fortran: PGI CUDA Fortran Compiler\n- Haskell: The accelerate package lists available CUDA backends\n- Java: JCuda\n- Mathematica: CUDAlink\n- Mono/.NET: CUDAfy.NET, managedCuda\n- Perl: KappaCUDA, CUDA-Minimal\n- Python: python-pycuda\n- Ruby: rbcuda\n- Rust: Rust-CUDA. Unmaintained: cuda-sys (bindings), RustaCUDA (high-level wrapper).\n\n"
    },
    {
      "title": "ROCm",
      "level": 2,
      "content": "ROCm (Radeon Open Compute) is AMD's open-source parallel computing architecture and framework. Although it requires an AMD GPU some ROCm tools are hardware agnostic. See the ROCm for Arch Linux repository for more information.\n\n- rocm-hip-sdk: Develop applications using HIP and libraries for AMD platforms.\n- rocm-opencl-sdk: Develop OpenCL-based applications for AMD platforms.\n\n"
    },
    {
      "title": "HIP",
      "level": 3,
      "content": "The Heterogeneous Interface for Portability (HIP) is AMD's dedicated GPU programming environment for designing high performance kernels on GPU hardware. HIP is a C++ runtime API and programming language that allows developers to create portable applications on different platforms.\n\n- rocm-hip-runtime: The base runtime, packages to run HIP applications on the AMD platform.\n- hip-runtime-amd: The Heterogeneous Interface for AMDGPUs in ROCm. Supports GPUs from the polaris architecture (RX 500 series) till AMD's latest RDNA 2 architecture (RX 6000 series)\n- miopen-hip: AMD's open source deep learning library with HIP backend.\n- hip-runtime-nvidia: The Heterogeneous Interface for NVIDIA GPUs in ROCm.\n\n"
    },
    {
      "title": "OpenMP",
      "level": 3,
      "content": "The openmp-extrasAUR package provides AOMP - an open source Clang/LLVM based compiler with added support for the OpenMP API on AMD GPUs.\n\n"
    },
    {
      "title": "OpenCL",
      "level": 3,
      "content": "The rocm-opencl-runtime package is the part of the ROCm framework providing an OpenCL runtime.\n\n"
    },
    {
      "title": "OpenCL image support",
      "level": 4,
      "content": "The latest ROCm versions now includes OpenCL Image Support used by GPGPU accelerated software such as Darktable. ROCm with the AMDGPU open source graphics driver are all that is required. AMDGPU PRO is not required.\n\n```\n$ /opt/rocm/bin/clinfo | grep -i \"image support\"\n```\n\n```\nImage support                                   Yes\n```\n\n"
    },
    {
      "title": "Troubleshooting",
      "level": 3,
      "content": "First check if your GPU shows up in /opt/rocm/bin/rocminfo. If it does not, it might mean that ROCm does not support your GPU or it is built without support for your GPU.\n\n"
    },
    {
      "title": "PyTorch",
      "level": 4,
      "content": "To use PyTorch with ROCm install python-pytorch-rocm\n\n```\n$ python -c 'import torch; print(torch.cuda.is_available())'\n```\n\n```\nTrue\n```\n\nROCm pretends to be CUDA so this should return True. If it does not, either it is not compiled with your GPU support or you might have conflicting dependencies. You can verify those by looking at ldd /usr/lib/libtorch.so - there should not be any missing .so files nor multiple versions of same .so.\n\n"
    },
    {
      "title": "List of GPGPU accelerated software",
      "level": 2,
      "content": "Note: **This article or section needs expansion.** This article or section needs expansion.\n\nThis article or section needs expansion.\n\n- Bitcoin\n- Blender – CUDA support for Nvidia GPUs and HIP support for AMD GPUs. More information here.\n- BOINC\n- FFmpeg – more information here.\n- Folding@home\n- GIMP – experimental – more information here.\n- HandBrake\n- Hashcat\n- LibreOffice Calc – more information here.\n- mpv - See mpv#Hardware video acceleration.\n- clinfo – Find all possible (known) properties of the OpenCL platform and devices available on the system.\n- cuda_memtestAUR – a GPU memtest. Despite its name, is supports both CUDA and OpenCL.\n- darktable – OpenCL feature requires at least 1 GB RAM on GPU and Image support (check output of clinfo command).\n- DaVinci Resolve - a non-linear video editor. Can use both OpenCL and CUDA.\n- imagemagick\n- lc0AUR - Used for searching the neural network (supports tensorflow, OpenCL, CUDA, and openblas)\n- opencv\n- pyritAUR\n- python-pytorch-cuda - PyTorch with CUDA backend\n- tensorflow-cuda - Port of TensorFlow to CUDA\n- tensorflow-computecppAUR - Port of TensorFlow to SYCL\n- xmrig - High Perf CryptoNote CPU and GPU (OpenCL, CUDA) miner\n\n"
    },
    {
      "title": "See also",
      "level": 2,
      "content": "- OpenCL official homepage\n- SYCL official homepage\n- SPIR official homepage\n- CUDA Toolkit homepage\n- Intel SDK for OpenCL Applications homepage\n- ComputeCpp official homepage\n- List of OpenCL frameworks applicable for different GPUs\n\n"
    }
  ]
}