{
  "title": "Touchscreen",
  "url": "https://wiki.archlinux.org/title/Touchscreen",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "Related articles\n\n- Calibrating Touchscreen\n\nIf you ever tried to set up a touchscreen device in Linux, you might have noticed that it is either working out of the box (besides some calibration), or is very tedious, especially when it is not supported by the kernel.\n\n"
    },
    {
      "title": "Introduction",
      "level": 2,
      "content": "This article assumes that your touchscreen device is supported by the kernel (e.g. by the usbtouchscreen module). That means there exists a /dev/input/event* node for your device. Check out\n\n```\n$ less /proc/bus/input/devices\n```\n\nto see if your device is listed or try\n\n```\n# cat /dev/input/event? # replace ? with the event numbers\n```\n\nfor every of your event nodes while touching the display. If you found the corresponding node, it is likely that you will be able to get the device working.\n\n"
    },
    {
      "title": "Available X11 drivers",
      "level": 2,
      "content": "There are a lot of touchscreen input drivers for X11 out there. The most common ones are in the extra repository:\n\n- xf86-input-evdev (likely the default driver if you plug in your touchscreen and it \"just works\")\n- xf86-input-libinput; see also libinput\n- xf86-input-elographics\n\nLess common drivers, not contained in the repository, are:\n\n- xf86-input-magictouch\n- xf86-input-mutouch\n- xf86-input-plpevtch\n- xf86-input-palmax\n\nProprietary drivers for some devices (e.g. xf86-input-egalax), were available at one point but have become unmaintained: use the open source drivers.\n\nDepending on your touchscreen device choose an appropriate driver. Again, evdev is likely to be the default if your touchscreen \"just works.\"\n\n"
    },
    {
      "title": "Two-fingers scrolling",
      "level": 2,
      "content": "The two-fingers scrolling has to be implemented on the application side (see this link). For Firefox, see Firefox/Tweaks#Enable touchscreen gestures.\n\nThere is a hack to emulates this scrolling behavior for every application in #Touchegg, but the X server still handles it as text selection (at least with Plasma).\n\n"
    },
    {
      "title": "Calibration",
      "level": 3,
      "content": "Install xinput_calibratorAUR (AUR). Then, run xinput_calibrator and follow the instructions.\n\n"
    },
    {
      "title": "Using a touchscreen in a multi-head setup",
      "level": 2,
      "content": "To use multiple displays (some of which are touchscreens), you need to tell Xorg the mapping between the touch surface and the screen. This can be achieved with xinput as follows.\n\nTake for example the setup of having a wacom tablet and an external monitor; xrandr shows both displays:\n\n```\n$ xrandr\n```\n\n```\nScreen 0: minimum 320 x 200, current 2944 x 1080, maximum 8192 x 8192\nLVDS1 connected 1024x768+0+0 (normal left inverted right x axis y axis) 0mm x 0mm\n   1024x768       60.0*+\n   800x600        60.3     56.2  \n   640x480        59.9  \nVGA1 connected 1920x1080+1024+0 (normal left inverted right x axis y axis) 477mm x 268mm\n   1920x1080      60.0*+\n   1600x1200      60.0  \n   1680x1050      60.0  \n   1680x945       60.0\n```\n\nYou see we have two displays here. LVDS1 and VGA1. LVDS1 is the display internal to the tablet, and VGA1 is the external monitor. We wish to map our stylus input to LVDS1. So we have to find the ID of the stylus input:\n\n```\n$ xinput --list\n```\n\n```\n⎡ Virtual core pointer                    \tid=2\t[master pointer  (3)]\n⎜   ↳ Virtual core XTEST pointer              \tid=4\t[slave  pointer  (2)]\n⎜   ↳ QUANTA OpticalTouchScreen               \tid=9\t[slave  pointer  (2)]\n⎜   ↳ TPPS/2 IBM TrackPoint                   \tid=11\t[slave  pointer  (2)]\n⎜   ↳ Serial Wacom Tablet WACf004 stylus      \tid=13\t[slave  pointer  (2)]\n⎜   ↳ Serial Wacom Tablet WACf004 eraser      \tid=14\t[slave  pointer  (2)]\n⎣ Virtual core keyboard                   \tid=3\t[master keyboard (2)]\n    ↳ Virtual core XTEST keyboard             \tid=5\t[slave  keyboard (3)]\n    ↳ Power Button                            \tid=6\t[slave  keyboard (3)]\n    ↳ Video Bus                               \tid=7\t[slave  keyboard (3)]\n    ↳ Sleep Button                            \tid=8\t[slave  keyboard (3)]\n    ↳ AT Translated Set 2 keyboard            \tid=10\t[slave  keyboard (3)]\n    ↳ ThinkPad Extra Buttons                  \tid=12\t[slave  keyboard (3)]\n```\n\nWe see that we have two stylus inputs. We now need to simply map our inputs to our output like so:\n\n```\n$ xinput --map-to-output 'Serial Wacom Tablet WACf004 stylus' LVDS1\n$ xinput --map-to-output 'Serial Wacom Tablet WACf004 eraser' LVDS1\n```\n\nYou can automate this by putting these commands in your ~/.xinitrc or similar. The mapping will be lost if the touchscreen is disconnected and re-connected, for example, when switching monitors via a KVM. In that case it is better to use a udev rule. The Calibrating Touchscreen page has an example udev rule for the case when a transformation matrix has been calculated manually and needs to be applied automatically.\n\n"
    },
    {
      "title": "Using xrandr-watch-git to automate map-to-output",
      "level": 3,
      "content": "There are xrandr events we can capture from a script. Install xrandr-watch-gitAUR, create a script ~/.xrandr-changed with execution permission to perform map-to-output, for example:\n\n```\n~/.xrandr-changed\n```\n\n```\n#!/bin/sh\nxinput --map-to-output \"Wacom HID 4861 Finger touch\" \"eDP1\"\n```\n\nand start, test and enable the systemd/User service xrandr-watcher.service.\n\n"
    },
    {
      "title": "Wayland/Weston",
      "level": 3,
      "content": "Wayland does not currently have a known method to lock touching to a specific display in any environment other than sway (or wlroots-based supported compositors). There are tools such as weston-touch-calibrator, but Gnome Wayland uses Xwayland leaving the calibrator unable to locate any touchscreen.\n\nWayland/Xwayland also masks the xinput list and funnels them down to generic xwayland devices such as \"xwayland-pointer\",\"xwayland-relative-pointer\",\"xwayland-touch-pointer\", etc. The Wayland method of \"Xinput\" is \"Libinput\", but does not have all the same functionality. The current known method to use touchscreens in a multi-head setup is to force Gnome or KDE to use X11. libinput currently assumes the touchscreen(s) covers all available monitors.\n\nSee Sway#Touch display mapping for settings in sway.\n\n"
    },
    {
      "title": "Touchegg",
      "level": 2,
      "content": "Touchegg is a multitouch gesture program, only compatible with X, that runs as a user in the background, recognizes gestures, and translates them to more conventional events such as mouse wheel movements, so that you can for example use two fingers to scroll. But it also interferes with applications or window managers which already do their own gesture recognition. If you have both a touchpad and a touchscreen, and if the touchpad driver (such as synaptics or libinput) has been configured not to recognize gestures itself, but to pass through the multi-touch events, then Touchegg will recognize gestures on both: this cannot be configured. In fact it does a better job of recognizing gestures than either the synaptics or libinput touchpad drivers; but on the touchscreen, it is generally better for applications to respond to touch in their own unique ways. Some Qt and GTK applications do that, but they will not be able to if you have Touchegg \"eating\" the touch events. So, Touchegg is useful when you are running mainly legacy applications which do not make their own use of touch events.\n\nThe two-fingers scrolling has been disabled in the recent rewrite of touchegg 2.0. To enable it, install xdotool and see this closed issue.\n\n"
    }
  ]
}