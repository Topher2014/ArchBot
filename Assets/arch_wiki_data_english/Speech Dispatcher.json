{
  "title": "Speech Dispatcher",
  "url": "https://wiki.archlinux.org/title/Speech_Dispatcher",
  "sections": [
    {
      "title": "Introduction",
      "level": 1,
      "content": "Related articles\n\n- Festival\n\nSpeech Dispatcher is a device independent layer for speech synthesis that provides a common easy to use interface for both client applications (programs that want to speak) and for software synthesizers (programs actually able to convert text to speech).\n\nIt is a part of the Free(b)soft project, which is intended to allow blind and visually impaired people to work with computer and Internet based on free software.\n\n"
    },
    {
      "title": "Installation",
      "level": 2,
      "content": "Install the speech-dispatcher package. Next, install one of several supported speech synthesizers.\n\nTo use Festival, install festival-freebsoft-utilsAUR. Follow configuration instructions in the dedicated section below.\n\nTo use a modern neural text to speech system Piper, install piper-tts-binAUR and one of the voice packages for your language, e.g. piper-voices-en-usAUR. Configure speech dispatcher to use Piper as described in the dedicated section below. Alternatively to the above AUR packages, Piper along with voices and the speech dispatcher configuration may be installed using Pied, an automated graphical installer distributed via Flatpak.\n\nTo use eSpeak NG, install espeakup and enable the service. Follow configuration instructions in the section below.\n\n"
    },
    {
      "title": "Configuration",
      "level": 2,
      "content": "The main configuration file is located at /etc/speech-dispatcher/speechd.conf however speech-dispatcher is usually run on a per user basis to allow for multiple users to have differing preferences. User configuration files are stored at ~/.config/speech-dispatcher/. There is also support to allow different speech synthesis engine clients to have their own configurations too.\n\nUse the included spd-conf tool to change configuration options. By default it will run in interactive mode and ask you a series of questions in order to generate the type of file you require. It is recommended that you create a per user configuration unless you are absolutely sure you will be the only user. Altering the system configuration requires root permissions.\n\n"
    },
    {
      "title": "Basic configuration",
      "level": 3,
      "content": "To use interactive mode and answer questions about what you need run the following:\n\n```\n$ spd-conf\n```\n\nTo create a per user configuration run the following:\n\n```\n$ spd-conf -uc\n```\n\nTo edit the system wide configuration file run the following:\n\n```\n# spd-conf -C\n```\n\n"
    },
    {
      "title": "Festival specific",
      "level": 3,
      "content": "Note: **The factual accuracy of this article or section is disputed.** The factual accuracy of this article or section is disputed.\n\nThe factual accuracy of this article or section is disputed.\n\nIf you intend to use Festival as your speech synthesis engine then you should also do the following:\n\n```\n$ $EDITOR ~/.config/speech-dispatcher/speechd.conf\n```\n\nFind and uncomment (by removing the # from in front of it) the line:\n\n```\n~/.config/speech-dispatcher/speechd.conf\n```\n\n```\n...\n#AddModule \"festival\"\n...\n```\n\nThen save the file.\n\n"
    },
    {
      "title": "Piper specific",
      "level": 3,
      "content": "Speech dispatcher supports Piper only through a generic interface module that interacts through a custom shell command. An audio player is necessary for this. For PulseAudio, install mpv; for ALSA, use aplay from alsa-utils.\n\nIn your user's speech-dispatcher configuration file (see earlier section for how to create it), add the module and configuration file for Piper:\n\n```\n~/.config/speech-dispatcher/speechd.conf\n```\n\n```\nAddModule \"piper-tts-generic\" \"sd_generic\" \"piper-tts-generic.conf\"\n```\n\nCreate the following module configuration file for Piper. In the shell command, edit the path to the model for your desired voice among those in /usr/share/piper-voices/, and the audio player appropriate for your audio back-end:\n\n```\n~/.config/speech-dispatcher/modules/piper-tts-generic.conf\n```\n\n```\nGenericExecuteSynth \"export XDATA=\\'$DATA\\'; echo \\\"$XDATA\\\" | sed -z 's/\\\\n/ /g' | piper-tts -q -m \\\"/usr/share/piper-voices/en/en_US/ryan/high/en_US-ryan-high.onnx\\\" -s 21 -f - | mpv --volume=80 --no-terminal --keep-open=no -\"\n\nAddVoice \"en-US\" \"MALE1\"   \"en_US-ryan-high\"\n```\n\nThe shell command needs to filter out the newlines, since piper-tts exits on newline. To accomplish this, the input text, which speech-dispatcher substitutes into the shell command as a literal string in place of the $DATA placeholder string, is first assigned to an environment variable, the contents of the variable is then piped into sed for substitution of the newline character with a space.\n\nA multi-voice setup can be realized utilizing the $VOICE variable. The following example assumes the appropriate .onnx and .onnx.json files are placed in a flat directory:\n\n```\n~/.config/speech-dispatcher/modules/piper-tts-generic.conf\n```\n\n```\nGenericExecuteSynth \"echo \\'$DATA\\' | piper-tts --model /path/to/piper-tts-voices/$VOICE -f - | mpv --no-terminal --keep-open=no -\"\n\nAddVoice \"de-DE\" \"male1\" \"de_DE-thorsten-high.onnx\"\n\nAddVoice \"en-US\" \"female1\" \"en_US-lessac-low.onnx\"\nAddVoice \"en-US\" \"male1\" \"en_US-ryan-medium.onnx\"\n\nDefaultVoice \"en_US-lessac-low.onnx\"\n```\n\n$VOICE is equal to the third argument provided to AddVoice - considered \"name\" of the voice - and must match the .onnx filename. If a client does not explicitly specify a voice then $VOICE equals no_voice. Set DefaultVoice as a fallback to catch that situation.\n\n"
    },
    {
      "title": "Socket activation",
      "level": 3,
      "content": "Speech Dispatcher from version 0.12.0 onwards allows activation via socket. This feature allows Flatpak applications such as Foliate, for example, to use the text-to-speech feature using Speech Dispatcher. To initialize the socket, run the following command:\n\n```\n$ systemctl start --user speech-dispatcher.socket\n```\n\nTo enable the socket at system startup, use the enable option instead of start.\n\n"
    },
    {
      "title": "Usage",
      "level": 2,
      "content": "Using speech-dispatcher directly is not a common scenario as its intended to provide an access layer to other speech synthesis engines, that said you can interact with it directly by using the included spd-say binary as follows:\n\n```\n$ spd-say \"Arch Linux is the best\"\n```\n\nThe Firefox browser is one of the applications that supports speech-dispatcher. Switch to reader view (Ctrl-Alt-R) and a button for narration (headphones icon) should be visible in the small menu. You may need to restart Firefox whenever speech-dispatcher daemon is started or restarted.\n\nThe Okular PDF viewer also supports speech-dispatcher. Select text in \"Text Selection\" mode, right-click it, and choose \"Speak Text\", or choose \"Speak Current Page\" in the Tools menu. You may need to restart Okular whenever speech-dispatcher daemon is started or restarted.\n\n"
    },
    {
      "title": "Logs",
      "level": 3,
      "content": "Speech-dispatcher writes very little to the system journal, however it does write useful information to its own logs. You can find the location of these in the output of this command:\n\n```\n$ /usr/bin/speech-dispatcher -l 3\n```\n\n"
    },
    {
      "title": "Spd-conf tests",
      "level": 3,
      "content": "spd-conf contains a routine to test the operation of speech-dispatcher, you can run it with the following command:\n\n```\n$ spd-conf -d\n```\n\nOr use the following to get a very verbose log dump:\n\n```\n$ spd-conf -D\n```\n\nOther tests are available, for example testing ALSA, PulseAudio and Festival, to see a full list of available options run the following:\n\n```\n$ spd-conf --help\n```\n\nMost of the available tests will run as part of the test routine.\n\n"
    },
    {
      "title": "Speech-dispatcher fails to start",
      "level": 3,
      "content": "The tests above won't work if speech-dispatcher fails to start. If you want more information than is in the logs you can attempt to start the server like this:\n\n```\n$ /usr/bin/speech-dispatcher -l 3\n```\n\nThis will output information about the startup process to the terminal.\n\n"
    },
    {
      "title": "Using TTS causes the dummy output module to speak an error message",
      "level": 3,
      "content": "Note: **This article or section needs expansion.** This article or section needs expansion.\n\nThis article or section needs expansion.\n\nThis happens when speech dispatcher cannot connect to the speech synthesis engine. If you are using Festival then it needs to be running as a server, this can be achieved with the following command:\n\n```\n$ festival --server &\n```\n\n"
    },
    {
      "title": "See also",
      "level": 2,
      "content": "- Online project documentation\n- Project Homepage - https://freebsoft.org/speechd\n- Project Github page - https://github.com/brailcom/speechd\n- Project documentation page (html source code) - https://github.com/brailcom/speechd/blob/master/doc/speech-dispatcher.html\n\n"
    }
  ]
}